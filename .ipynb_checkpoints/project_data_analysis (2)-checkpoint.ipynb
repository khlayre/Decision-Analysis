{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv does not exist: '/Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ed719a5fd760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv does not exist: '/Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'/Users/corneliusashley-osuzoka/Downloads/correct_project_data_2.csv', skiprows = [i for i in range(1, 3) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(direction, strength):\n",
    "        \n",
    "        # create array for pairwise comparison (PC)\n",
    "        pc = np.zeros(len(strength))\n",
    "        length = len(strength)\n",
    "        for i in range(0, int(length)):\n",
    "            d = direction[int(i)]\n",
    "            s = 2\n",
    "            if strength[int(i)] != 0:\n",
    "                s = strength[int(i)]\n",
    "            if d == 1:\n",
    "                pc[int(i)] = s\n",
    "            elif d == 2:\n",
    "                pc[int(i)] = (1/s)\n",
    "            else:\n",
    "                pc[int(i)] = 1      \n",
    "\n",
    "        # create pairwise comparison matrix (PCM)\n",
    "        pcm = np.array([\n",
    "            [1, pc[0], pc[1], pc[2]],\n",
    "            [1/pc[0], 1, pc[3], pc[4]],\n",
    "            [1/pc[1], 1/pc[3], 1, pc[5]],\n",
    "            [1/pc[2], 1/pc[4], 1/pc[5], 1]\n",
    "        ])\n",
    "\n",
    "        # create rgm array\n",
    "        rgm = np.zeros(len(pcm))\n",
    "        sigma_rgm = 0\n",
    "        for i in range(0, int(len(rgm))):\n",
    "            rgm[i] = 1\n",
    "            for j in range(0, int(len(pcm[i]))): \n",
    "                rgm[i] = np.dot(rgm[i],pcm[i][j])\n",
    "            rgm[i] = rgm[i]**(1/len(pcm))\n",
    "            sigma_rgm = rgm[i]+ sigma_rgm\n",
    "\n",
    "        # create gm array\n",
    "        gm = np.zeros(len(pcm))\n",
    "        for i in range(0, int(len(rgm))):\n",
    "            gm[i] = (rgm[i])/(sigma_rgm)\n",
    "\n",
    "        # get factor weightings\n",
    "        Factor1 = round(100*gm[0])\n",
    "        Factor2 = round(100*gm[1])\n",
    "        Factor3 = round(100*gm[2])\n",
    "        Factor4 = round(100*gm[3])\n",
    "\n",
    "        return [Factor1, Factor2, Factor3, Factor4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_analysis():\n",
    "    \n",
    "    for row in data:\n",
    "        df_1 = pd.DataFrame(data, columns=[\"Q1\",\"Q2\",\"Q3\",\"Q4\",\"Q5\",\"Q6\",\"Q1a\",\"Q2a\",\"Q3a\",\"Q4a\",\"Q5a\",\"Q6a\"])\n",
    "        df_2 = pd.DataFrame(data, columns=[\"Q9\",\"Q10\",\"Q11\",\"Q12\",\"Q13\",\"Q14\",\"Q9a\",\"Q10a\",\"Q11a\",\"Q12a\",\"Q13a\",\"Q14a\"])\n",
    "        df_3 = pd.DataFrame(data, columns=[\"Q17\",\"Q18\",\"Q19\",\"Q20\",\"Q21\",\"Q22\",\"Q17a\",\"Q18a\",\"Q19a\",\"Q20a\",\"Q21a\",\"Q22a\"])\n",
    "    project_data_1, project_data_2, project_data_3 = df_1,df_2,df_3\n",
    "\n",
    "\n",
    "    \n",
    "    updated_df_1 = pd.DataFrame(columns = ['Cost of Car', 'Features', 'Durability', 'Brand'])\n",
    "    updated_df_2 = pd.DataFrame(columns = ['Cost of Fashion', 'Ethical Supply chain', 'Range of Products', 'Quality'])\n",
    "    updated_df_3 = pd.DataFrame(columns = ['Cost', 'Ease of Entry', 'Historical Sites', 'Safety'])\n",
    "    \n",
    "    #update range value to the last row index in the data set.\n",
    "    for i in range(46):\n",
    "        direction_1 = np.array(df_1.iloc[int(i), 0:6])\n",
    "        strength_1 = np.array(df_1.iloc[int(i), 6:])\n",
    "        \n",
    "        direction_2 = np.array(df_2.iloc[int(i), 0:6])\n",
    "        strength_2 = np.array(df_2.iloc[int(i), 6:])\n",
    "        \n",
    "        direction_3 = np.array(df_3.iloc[int(i), 0:6])\n",
    "        strength_3 = np.array(df_3.iloc[int(i), 6:])\n",
    "        \n",
    "        processed1 = data_processing(direction_1, strength_1)\n",
    "        processed2 = data_processing(direction_2, strength_2)\n",
    "        processed = data_processing(direction_3, strength_3)\n",
    "        \n",
    "        updated_df_1 = updated_df_1.append({'Cost of Car': processed1[0], 'Features': processed1[1], \n",
    "                                            'Durability': processed1[2], 'Brand': processed1[3]}, ignore_index=True)\n",
    "        updated_df_2 = updated_df_2.append({'Cost of Fashion': processed2[0], 'Ethical Supply chain': processed2[1], \n",
    "                         'Range of Products': processed2[2], 'Quality': processed2[3]}, ignore_index=True)\n",
    "        updated_df_3 = updated_df_3.append({'Cost': processed[0], 'Ease of Entry': processed[1], \n",
    "                     'Historical Sites': processed[2], 'Safety': processed[3]}, ignore_index=True)\n",
    "        \n",
    "    frames = [updated_df_1, updated_df_2, updated_df_3]\n",
    "    result = pd.concat(frames,axis=1, join=\"inner\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = question_analysis()\n",
    "a = pd.DataFrame(analysis)\n",
    "\n",
    "# update directory for file export\n",
    "a.to_csv('/Users/corneliusashley-osuzoka/Downloads/solution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 2 2 2 3]\n",
      "[7 8 8 8 8 7]\n",
      "{'Cost of Fashion': 9, 'Ethical Supply chain': 3, 'Range of Products': 44, 'Quality': 44}\n"
     ]
    }
   ],
   "source": [
    "# not an actual logger, just a logger for the direction, strength and final analysis of question 2 \n",
    "def logger(entry):\n",
    "    for row in data:\n",
    "        df_2 = pd.DataFrame(data, columns=[\"Q9\",\"Q10\",\"Q11\",\"Q12\",\"Q13\",\"Q14\",\"Q9a\",\"Q10a\",\"Q11a\",\"Q12a\",\"Q13a\",\"Q14a\"])\n",
    "    \n",
    "    data_store = {}\n",
    "    \n",
    "    direction = np.array(df_2.iloc[int(entry), 0:6])\n",
    "    strength = np.array(df_2.iloc[int(entry), 6:])\n",
    "    \n",
    "    processed = data_processing(direction, strength)\n",
    "    \n",
    "    data_store['Cost of Fashion'] = processed[0]\n",
    "    data_store['Ethical Supply chain'] = processed[1]\n",
    "    data_store['Range of Products'] = processed[2]\n",
    "    data_store['Quality'] = processed[3]\n",
    "    \n",
    "    print(direction)\n",
    "    print(strength)\n",
    "    return data_store\n",
    "\n",
    "print(logger(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
